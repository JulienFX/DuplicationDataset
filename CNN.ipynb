{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62a0411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network from scratch \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01160a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mnist_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf7cff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data) # transform our csv into array \n",
    "lines, cols = data.shape # lines = 42000 / columns = 785 bcz the images are 28x28=784 pixels +1 with the beggining cols of label\n",
    "np.random.shuffle(data) # because the train data are possibly sorted with a sequences of 0 then 1 then 2 and so on \n",
    "# we shuffe the dataset in order to avoid overfitting\n",
    "data_validation = data[0:1000].T # Data transposition is performed in this particular context to facilitate \n",
    "# the manipulation of examples and features. Some machine learning algorithms and libraries prefer \n",
    "# this matrix representation with examples in columns rather than rows.\n",
    "# data validation variable is used to evaluate and confirm the performance of our future model while training\n",
    "label_val = data_validation[0]\n",
    "result_val = data_validation[1:cols]\n",
    "result_val = result_val / 255. # we normalise between 0 and 1 in order to facilitate the process of learning\n",
    "# The dot is here to indicate that the division should be done with a decimal precision\n",
    "\n",
    "data_train = data[1000:lines].T\n",
    "label_train = data_train[0] # we did the transpose so the first line is compose only by label\n",
    "result_train = data_train[1:cols]\n",
    "result_train = result_train / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "88aa1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params() :\n",
    "    # W => weights / b => bias ... In the beginning both are generated randomly \n",
    "    # 1st param : nb neurons on the actual layer / 2st param : nb neurons of the previous layer\n",
    "    neuronsLayerOne = 10 \n",
    "    neuronsLayerTwo = 10\n",
    "    W1 = np.random.rand(neuronsLayerOne,cols-1) -0.5 # -1 => to understand refer to what we said on the line of creation of cols\n",
    "    b1 = np.random.rand(neuronsLayerOne,1) - 0.5 # which means for each neurons we generate a random number which will corresponding to the bias\n",
    "    # bias doesn't have to be necessary between 0 and 1 ! \n",
    "    W2 = np.random.rand(neuronsLayerTwo,neuronsLayerOne) -0.5\n",
    "    b2 = np.random.rand(neuronsLayerTwo,1) -0.5\n",
    "    # - 0.5 is in reality not necessary but bcz these params are gonna be use in softmax function \n",
    "    # which include exponential if we've got a too big number, the exponential will be too hard to compute for the computer \n",
    "    # In other words - 0.5 is only here due to computer's performance \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLu(Z) : #activation function non linear \n",
    "    return np.maximum(Z,0)\n",
    "\n",
    "def softmax(Z) : \n",
    "    return np.exp(Z)/sum(np.exp(Z))\n",
    "\n",
    "def deriv_ReLu(Z) :\n",
    "    return Z>0\n",
    "\n",
    "def forward_propagation(W1, b1, W2, b2, X) : # X is the input data (pixels 1 image) / Z -> unactivated layer / A -> activated \n",
    "    # forward propagation is when you take images and run them through the CNN / It's a linear transformation\n",
    "    Z1 = W1.dot(X)+b1 # X -> several lines and 1 column due to the transpose ! (l,c) x (l,c)  W1 -> l : 1 c : 10 \n",
    "    # we tend to represent layer of CNN in line but we do not need to adapt this in our line of code bcz it's not important\n",
    "    A1 = ReLu(Z1)\n",
    "    Z2 = W2.dot(A1)+b2\n",
    "    A2 = softmax(Z2) # final result \n",
    "    # final result Y of our CNN will be score associated to each prediction such as this\n",
    "    # [0 0.05 0.7 0.01 0.09 0.1 0 0.05 0 0] = total equals to 1 such as a distribution function !\n",
    "    'RESUME : '\n",
    "    'Forward propagation for image is taking all the pixels of the image and applying them'\n",
    "    'some operations :'\n",
    "    'SUM (Entry pixels X Weight + bias)'\n",
    "    'Non linearity => activation function (ReLu and softmax here) '\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def one_hot(Y) : # function that will take the label of our data and for each label transform it into an encoded matrix \n",
    "    # example : 0 : 100000000 / 4 : 0000100000 / 9 : 0000000001 ...\n",
    "    labelsNb = 10 # 0 1 2 3 4 5 6 7 8 9\n",
    "    one_hot_Y = np.zeros((Y.size, labelsNb)) # to specify tuple we put () / Y.size => number of values of labels that we pass to the function \n",
    "    one_hot_Y[np.arange(Y.size),Y] = 1 \n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def backward_propagation(Z1, A1, Z2, A2, W1, W2, X, Y) : \n",
    "    m = Y.size # equals line\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y # value of the error \n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2) # average of the absolute error \n",
    "    dZ1 = W2.T.dot(dZ2) * deriv_ReLu(Z1) #TO define \n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1)\n",
    "    'Documentation'\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha): \n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1    \n",
    "    W2 = W2 - alpha * dW2  \n",
    "    b2 = b2 - alpha * db2  \n",
    "    'Documentation'\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aefe9e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_propagation(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_propagation(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b95e626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[6 8 6 ... 6 5 6] [1 0 9 ... 8 1 9]\n",
      "0.09501694915254237\n",
      "Iteration:  10\n",
      "[8 0 8 ... 8 1 6] [1 0 9 ... 8 1 9]\n",
      "0.16740677966101694\n",
      "Iteration:  20\n",
      "[8 0 8 ... 8 1 8] [1 0 9 ... 8 1 9]\n",
      "0.2377457627118644\n",
      "Iteration:  30\n",
      "[1 0 8 ... 1 1 8] [1 0 9 ... 8 1 9]\n",
      "0.31213559322033896\n",
      "Iteration:  40\n",
      "[1 0 4 ... 8 1 4] [1 0 9 ... 8 1 9]\n",
      "0.3722033898305085\n",
      "Iteration:  50\n",
      "[1 0 4 ... 8 1 4] [1 0 9 ... 8 1 9]\n",
      "0.42338983050847456\n",
      "Iteration:  60\n",
      "[1 0 4 ... 8 1 4] [1 0 9 ... 8 1 9]\n",
      "0.4626271186440678\n",
      "Iteration:  70\n",
      "[1 0 4 ... 8 1 4] [1 0 9 ... 8 1 9]\n",
      "0.4980508474576271\n",
      "Iteration:  80\n",
      "[1 0 9 ... 8 1 4] [1 0 9 ... 8 1 9]\n",
      "0.5294745762711864\n",
      "Iteration:  90\n",
      "[1 0 9 ... 8 1 4] [1 0 9 ... 8 1 9]\n",
      "0.5557966101694916\n",
      "Iteration:  100\n",
      "[1 0 9 ... 8 1 4] [1 0 9 ... 8 1 9]\n",
      "0.5802881355932203\n",
      "Iteration:  110\n",
      "[1 0 9 ... 8 1 4] [1 0 9 ... 8 1 9]\n",
      "0.6001694915254238\n",
      "Iteration:  120\n",
      "[1 0 9 ... 8 1 4] [1 0 9 ... 8 1 9]\n",
      "0.6181525423728813\n",
      "Iteration:  130\n",
      "[1 0 9 ... 8 1 4] [1 0 9 ... 8 1 9]\n",
      "0.6335593220338983\n",
      "Iteration:  140\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.6476610169491526\n",
      "Iteration:  150\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.6593389830508475\n",
      "Iteration:  160\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.671542372881356\n",
      "Iteration:  170\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.6820508474576271\n",
      "Iteration:  180\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.6914237288135593\n",
      "Iteration:  190\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.6997457627118644\n",
      "Iteration:  200\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7076610169491525\n",
      "Iteration:  210\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7145084745762712\n",
      "Iteration:  220\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7206271186440678\n",
      "Iteration:  230\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7268305084745763\n",
      "Iteration:  240\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7323220338983051\n",
      "Iteration:  250\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7372372881355932\n",
      "Iteration:  260\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7427457627118644\n",
      "Iteration:  270\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7471525423728813\n",
      "Iteration:  280\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7514576271186441\n",
      "Iteration:  290\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.755593220338983\n",
      "Iteration:  300\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7595762711864407\n",
      "Iteration:  310\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7634237288135594\n",
      "Iteration:  320\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7669152542372881\n",
      "Iteration:  330\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7702033898305085\n",
      "Iteration:  340\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7737796610169492\n",
      "Iteration:  350\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7773389830508475\n",
      "Iteration:  360\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7805254237288135\n",
      "Iteration:  370\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7838644067796611\n",
      "Iteration:  380\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7868305084745763\n",
      "Iteration:  390\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7898305084745763\n",
      "Iteration:  400\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7931694915254237\n",
      "Iteration:  410\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7959830508474576\n",
      "Iteration:  420\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.7988135593220339\n",
      "Iteration:  430\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.8015084745762712\n",
      "Iteration:  440\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.8044915254237288\n",
      "Iteration:  450\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.8067118644067797\n",
      "Iteration:  460\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.8090847457627118\n",
      "Iteration:  470\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.8114406779661016\n",
      "Iteration:  480\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.8135932203389831\n",
      "Iteration:  490\n",
      "[1 0 9 ... 8 1 9] [1 0 9 ... 8 1 9]\n",
      "0.8154576271186441\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(result_train,label_train,  0.10, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b4b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
